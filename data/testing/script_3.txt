Donc maintenant on veut faire notre, on veut construire notre modèle. Donc pour ça, on va faire une phase de featuring engineering. Donc la phase de featuring engineering, c'est-à-dire qu'on va peut-être recréer des nouvelles features à partir de celle qu'on a, parce que ça nous semble pertinent par exemple, je sais pas on a des données avec un code postal et on se dit ça serait bien d'avoir le numéro du département, bon bah voilà on peut le faire dans cette phase-là. On peut faire plein d’autres choses. Une fois qu'on a fait ça, on va séparer notre jeu de données en trois parties. En train, validation et test. Bon il y a pas vraiment de règle sur la proportion, mais je dirais que 60% pour du train 20 % pour de la validation et 20% pour du test c’est plutôt bien. Donc là on va prendre notre jeu train, et puis on va construire un modèle. Et puis on va, donc un modèle, ça a un hyper paramétrage donc on va mettre quelques hyper paramètres. De là on construit le modèle donc on a notre modèle. Là on va prendre le jeu de validation. Le jeu de validation il n'a pas du tout servi à construire le modèle donc le modèle ne connaît pas ses données, elles sont nouvelles pour elle, c'est un peu comme si on faisait une phase de prédiction. En fait cette phase-là, elle nous permet, donc de récupérer un résultat, et de voir si notre algorithme il est généralisable. Si vous vous souvenez de la courbe de la maison, c'est, on est exactement dans ce cas-là. Donc le but c'est d'avoir un modèle qui est le plus généralisables possible. Donc là on peut avoir des phases de cross validation, de différents types de validation, mais on va pas rentrer dans le domaine, dans le truc maintenant. Donc une fois qu'on a nos résultats de la validation, soit ils sont corrects et c'est super, mais souvent ça marche pas comme ça, c'est un processus assez long et assez itératif, souvent on a besoin d'aller rebouger un petit peu les features. En recréer des nouvelles ou en enlever. Tuner les hyper paramètres, donc essayer de les affiner, donc ça c'est un travail qui est assez long. Et on fait ça autant de fois que nécessaire jusqu'à temps d'avoir un résultat de validation qui semble à peu près correcte. Donc le résultat de la validation, on sait qu'il est correct. Vous vous souvenez de l’indice de performance du début, bah en fait c'est quand notre indice de performance il correspond à ce qu’on attend. Donc une fois qu'on a fait ça, pour être sûr que notre modèle, en fait, il ait pas trop appris de notre jeu de validation, on garde un jeu de données qu'on appelle test et ce jeu-là on le redonne au modèle, et on récupère un résultat, et on compare pour voir que, pour voir si on a bien un modèle qui est généralisable sur un nouveau jeu de données. Donc voilà un petit peu le processus pour faire du machine learning, enfin pour la phase d’apprentissage.