On va maintenant voir ensemble les différentes couches de réseaux de neurones à connaître. Donc ici il y en a 7 principales. Je n'ai pas parlé de la couche d'entrée, je n'ai pas parlé de la couche de sortie. La première couche à connaître c’est la couche dense. Une couche dense c’est une couche dans laquelle les neurones sont complètement connectés entre eux et c'est la couche de base en deep learning qui est utilisé dans le modèle MPL perceptron multicouches. 2e couche c'est ce qu'on appelle la couche de convolution. Si vous avez déjà entendu parlé de réseaux de neurones convolutionnel, c'est parce qu'il y a une couche de convolution et la couche de convolution en général, permet d’extraire les caractéristiques issues des images. Donc la couche de convolution permet d'extraire des caractéristiques sur les images, c'est justement utilisé en computer vision, les réseaux de neurones convolutionnels. La troisième couche à connaître c’est la couche de récurrence recurrent layer, qui est très utilisé pour les données de séquence, justement sur les travaux de NLP, en général on va utiliser des couches de récurrence. 3e couche la couche de pooling qui permet de réduire en fait la taille des données utilisées dans les CNN, les réseaux de neurones convolutionnels. Et ensuite vous avez la couche de normalisation, comme son nom l'indique, ça va permettre de normaliser les données. Vous avez la couche de régularisation. Ici c'est pour éviter l’overfitting dans les réseaux de neurones, on en reparlera plus tard, mais globalement on peut ajouter des couches qui vont appliquer des paramètres de régularisation l1 l2. Et enfin vous avez la couche d'attention qui permet souvent d'améliorer les réseaux de neurones récurrents. Voilà les 7 principales couches à connaître, il y en a d'autres qu'on verra durant ce challenge.